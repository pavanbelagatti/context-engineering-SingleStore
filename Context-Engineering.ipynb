{"cells":[{"cell_type":"markdown","id":"b0632660-67dc-4cc4-b3b6-2285945a6f60","metadata":{"language":"python"},"source":["## Building Context Aware Workflows with SingleStore"]},{"cell_type":"markdown","id":"b8c96e8a-d3a2-46b5-9778-193d5185598d","metadata":{"language":"python"},"source":["### Step 1: Install Required Packages & Dependencies"]},{"cell_type":"code","execution_count":11,"id":"3635b469-72ef-4ee0-930d-8994a603fd56","metadata":{"execution":{"iopub.execute_input":"2025-10-06T07:30:59.881825Z","iopub.status.busy":"2025-10-06T07:30:59.881453Z","iopub.status.idle":"2025-10-06T07:31:05.995346Z","shell.execute_reply":"2025-10-06T07:31:05.994503Z","shell.execute_reply.started":"2025-10-06T07:30:59.881795Z"},"language":"python","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["pip install openai langchain langchain-community langchain-openai singlestoredb --quiet"]},{"cell_type":"markdown","id":"c3037caa-a16f-42e8-9649-39bc89c2baae","metadata":{"language":"python"},"source":["### Step 2: Import Required Libraries and Initialize Components"]},{"cell_type":"code","execution_count":10,"id":"a53c7202-e2e1-44e1-a62f-be4914158909","metadata":{"execution":{"iopub.execute_input":"2025-10-03T12:30:36.094391Z","iopub.status.busy":"2025-10-03T12:30:36.093858Z","iopub.status.idle":"2025-10-03T12:30:37.219036Z","shell.execute_reply":"2025-10-03T12:30:37.218189Z","shell.execute_reply.started":"2025-10-03T12:30:36.094363Z"},"language":"python","trusted":true},"outputs":[],"source":["from langchain_openai import OpenAIEmbeddings  # works after installing langchain-openai\n","from langchain_community.vectorstores import SingleStoreDB\n","from openai import OpenAI"]},{"cell_type":"markdown","id":"48de511b-990c-4ba3-81bb-f4ac3c4991cc","metadata":{"language":"python"},"source":["### Step 3: Set Up SingleStore and OpenAI Credentials"]},{"cell_type":"code","execution_count":12,"id":"b64d30dd-8af2-4bd1-ac88-161cb11b3026","metadata":{"execution":{"iopub.execute_input":"2025-10-03T12:32:41.142703Z","iopub.status.busy":"2025-10-03T12:32:41.142417Z","iopub.status.idle":"2025-10-03T12:32:41.146834Z","shell.execute_reply":"2025-10-03T12:32:41.146236Z","shell.execute_reply.started":"2025-10-03T12:32:41.142676Z"},"language":"python","trusted":true},"outputs":[],"source":["SINGLESTORE_HOST = \"Add host URL\"   # your host\n","SINGLESTORE_USER = \"admin\"                     # your user\n","SINGLESTORE_PASSWORD = \"Add your SingleStore DB password\"    # your password\n","SINGLESTORE_DATABASE = \"context_engineering\"   # your database\n","OPENAI_API_KEY = \"Add your OpenAI API key\""]},{"cell_type":"markdown","id":"ca3c3a41-b889-414e-8178-582d467b4536","metadata":{"language":"python"},"source":["### Step 4: Connect to the SingleStore Database"]},{"cell_type":"code","execution_count":13,"id":"5fa21c2e-8f33-468e-b6a8-c3ccbaa9e9d8","metadata":{"execution":{"iopub.execute_input":"2025-10-03T12:33:10.453858Z","iopub.status.busy":"2025-10-03T12:33:10.453538Z","iopub.status.idle":"2025-10-03T12:33:10.457624Z","shell.execute_reply":"2025-10-03T12:33:10.456992Z","shell.execute_reply.started":"2025-10-03T12:33:10.453829Z"},"language":"python","trusted":true},"outputs":[],"source":["connection_string = f\"mysql://{SINGLESTORE_USER}:{SINGLESTORE_PASSWORD}@{SINGLESTORE_HOST}:3306/{SINGLESTORE_DATABASE}\""]},{"cell_type":"markdown","id":"80dd4013-4cad-405a-9a7e-08b56c8fc685","metadata":{"language":"python"},"source":["### Step 5: Initialize Embeddings and OpenAI Client"]},{"cell_type":"code","execution_count":14,"id":"ad8fcdb5-15ea-43f2-b1e6-bb538d2238f4","metadata":{"execution":{"iopub.execute_input":"2025-10-03T12:33:25.070567Z","iopub.status.busy":"2025-10-03T12:33:25.070184Z","iopub.status.idle":"2025-10-03T12:33:25.274486Z","shell.execute_reply":"2025-10-03T12:33:25.273948Z","shell.execute_reply.started":"2025-10-03T12:33:25.070528Z"},"language":"python","trusted":true},"outputs":[],"source":["embeddings = OpenAIEmbeddings(api_key=OPENAI_API_KEY)\n","client = OpenAI(api_key=OPENAI_API_KEY)"]},{"cell_type":"markdown","id":"f12e9117-3969-4e45-aa5f-f2c789b7112b","metadata":{"language":"python"},"source":["### Step 6: Initialize the SingleStore Vector Database"]},{"cell_type":"code","execution_count":17,"id":"593f67cd-eeb6-441d-a450-420bc03566fd","metadata":{"execution":{"iopub.execute_input":"2025-10-03T12:36:52.094511Z","iopub.status.busy":"2025-10-03T12:36:52.094137Z","iopub.status.idle":"2025-10-03T12:36:55.236003Z","shell.execute_reply":"2025-10-03T12:36:55.235125Z","shell.execute_reply.started":"2025-10-03T12:36:52.094475Z"},"language":"python","trusted":true},"outputs":[],"source":["from langchain_community.vectorstores import SingleStoreDB\n","from langchain_openai import OpenAIEmbeddings\n","\n","embeddings = OpenAIEmbeddings(api_key=OPENAI_API_KEY)\n","\n","vectorstore = SingleStoreDB(\n","    embedding=embeddings,\n","    table_name=\"context_memory\",\n","    host=SINGLESTORE_HOST,\n","    user=SINGLESTORE_USER,\n","    password=SINGLESTORE_PASSWORD,\n","    database=SINGLESTORE_DATABASE,\n","    port=3306\n",")"]},{"attachments":{},"cell_type":"markdown","id":"b578b730-ee35-442a-bffc-beeddab603cb","metadata":{"language":"python"},"source":["### Step 7: Insert Knowledge into Long-Term Memory"]},{"cell_type":"code","execution_count":18,"id":"ffee895b-18c6-42f2-9a8e-75ea96e65905","metadata":{"execution":{"iopub.execute_input":"2025-10-03T12:37:38.713378Z","iopub.status.busy":"2025-10-03T12:37:38.713031Z","iopub.status.idle":"2025-10-03T12:37:43.297832Z","shell.execute_reply":"2025-10-03T12:37:43.297076Z","shell.execute_reply.started":"2025-10-03T12:37:38.713353Z"},"language":"python","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n","INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n","INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"]},{"name":"stdout","output_type":"stream","text":["âœ… Knowledge inserted into SingleStore\n"]}],"source":["docs = [\n","    {\"id\": \"1\", \"text\": \"SingleStore unifies SQL and vector search in a single engine.\"},\n","    {\"id\": \"2\", \"text\": \"Context engineering ensures AI agents always have the right context at the right time.\"},\n","    {\"id\": \"3\", \"text\": \"SingleStore is ideal for real-time RAG pipelines due to low-latency queries.\"}\n","]\n","\n","# Insert into vector DB\n","vectorstore.add_texts([d[\"text\"] for d in docs], ids=[d[\"id\"] for d in docs])\n","print(\"âœ… Knowledge inserted into SingleStore\")"]},{"attachments":{},"cell_type":"markdown","id":"993ccdb9-f6ea-4cb6-9b90-bd91afca1454","metadata":{"language":"python"},"source":["### Step 8: Retrieve Relevant Context"]},{"cell_type":"code","execution_count":19,"id":"57add9de-fb67-4903-bbd6-f5c0d7942596","metadata":{"execution":{"iopub.execute_input":"2025-10-03T12:37:56.592309Z","iopub.status.busy":"2025-10-03T12:37:56.591792Z","iopub.status.idle":"2025-10-03T12:37:58.936025Z","shell.execute_reply":"2025-10-03T12:37:58.935447Z","shell.execute_reply.started":"2025-10-03T12:37:56.592266Z"},"language":"python","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n","INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"]},{"name":"stdout","output_type":"stream","text":["ðŸ”¹ Retrieved Context:\n","- SingleStore is ideal for real-time RAG pipelines due to low-latency queries.\n","- SingleStore unifies SQL and vector search in a single engine.\n"]}],"source":["query = \"Why is SingleStore useful for context engineering?\"\n","results = vectorstore.similarity_search(query, k=2)\n","\n","print(\"ðŸ”¹ Retrieved Context:\")\n","for r in results:\n","    print(\"-\", r.page_content)"]},{"attachments":{},"cell_type":"markdown","id":"6cce084f-4bb7-471e-8a4b-3e51519e3046","metadata":{"language":"python"},"source":["### Step 9: Build Prompt for LLM"]},{"cell_type":"code","execution_count":20,"id":"d6917604-b8d8-4432-b716-52fd4b6fe5d0","metadata":{"execution":{"iopub.execute_input":"2025-10-03T12:38:14.287226Z","iopub.status.busy":"2025-10-03T12:38:14.286681Z","iopub.status.idle":"2025-10-03T12:38:28.742662Z","shell.execute_reply":"2025-10-03T12:38:28.742185Z","shell.execute_reply.started":"2025-10-03T12:38:14.287200Z"},"language":"python","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"]},{"name":"stdout","output_type":"stream","text":["ðŸ”¹ Agent Answer:\n"," Context engineering in the realm of artificial intelligence and data management involves preparing and optimizing data for use in context-aware applications, such as real-time retrieval-augmented generation (RAG) systems. When leveraging SingleStore for this purpose, it's essential to highlight key features that make it a powerful tool.\n","\n","1. **Low-Latency Queries**: SingleStore is optimized for real-time data processing, which is crucial for RAG applications that rely on immediate access to relevant context. This allows the system to retrieve and analyze data quickly, enabling rapid response times and enhancing user experience.\n","\n","2. **Unified SQL and Vector Search**: One of SingleStore's standout features is its ability to handle both SQL queries and vector searches within the same engine. This unification simplifies the data workflow, allowing developers to seamlessly integrate structured data (managed through SQL) with unstructured data (accessed via vector search). \n","\n","   - **SQL**: Useful for structured data queries, enabling traditional relational database functionalities.\n","   - **Vector Search**: Crucial for dealing with high-dimensional data often used in machine learning applications (like embeddings), making it easier to perform similarity searches and retrieve relevant information based on user queries.\n","\n","3. **Data Preparation and Contextualization**: Through the ability to combine both structured and unstructured data retrieval, context engineering can focus on enriching the user experience. By fine-tuning how data is indexed and retrieved, developers can ensure that the most relevant context is available for AI models and applications in real-time.\n","\n","4. **Performance and Scalability**: SingleStoreâ€™s architecture is designed to scale seamlessly, catering to a high volume of concurrent users and data. This capability allows organizations to handle varying workloads efficiently, crucial for applications needing to deliver consistent performance under different operational demands.\n","\n","Overall, context engineering using SingleStore enables the construction of sophisticated, responsive applications that require immediate access to both structured and unstructured context for enhanced AI-driven decision-making and interactions.\n"]}],"source":["from openai import OpenAI\n","client = OpenAI(api_key=OPENAI_API_KEY)\n","\n","user_input = \"Explain context engineering using SingleStore.\"\n","\n","context = \"\\n\".join([r.page_content for r in results])\n","\n","prompt = f\"\"\"\n","You are a helpful AI agent.\n","User asked: {user_input}\n","Relevant context from memory:\n","{context}\n","\"\"\"\n","\n","response = client.chat.completions.create(\n","    model=\"gpt-4o-mini\",\n","    messages=[{\"role\": \"user\", \"content\": prompt}]\n",")\n","\n","print(\"ðŸ”¹ Agent Answer:\\n\", response.choices[0].message.content)"]},{"attachments":{},"cell_type":"markdown","id":"5aee33b2-6177-488b-bb62-6118c1305e92","metadata":{"language":"python"},"source":["### Step 10: Store Conversation Back (Short-Term â†’ Long-Term Memory)"]},{"cell_type":"code","execution_count":21,"id":"3d3d9e01-4b2f-40b0-ada7-cda2d672fc8e","metadata":{"execution":{"iopub.execute_input":"2025-10-03T12:38:53.657587Z","iopub.status.busy":"2025-10-03T12:38:53.656990Z","iopub.status.idle":"2025-10-03T12:38:54.848425Z","shell.execute_reply":"2025-10-03T12:38:54.847820Z","shell.execute_reply.started":"2025-10-03T12:38:53.657559Z"},"language":"python","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n","INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"]},{"name":"stdout","output_type":"stream","text":["âœ… Conversation stored back into SingleStore for future retrieval\n"]}],"source":["vectorstore.add_texts([\n","    f\"User: {user_input}\", \n","    f\"Assistant: {response.choices[0].message.content}\"\n","])\n","\n","print(\"âœ… Conversation stored back into SingleStore for future retrieval\")"]},{"attachments":{},"cell_type":"markdown","id":"97815b46-bf0d-4044-b00e-c2926a80b0b6","metadata":{"language":"python"},"source":["### Step 11: Test Retrieval Again"]},{"cell_type":"code","execution_count":22,"id":"8df0f827-2eb7-4c44-aa78-374d9f62f38a","metadata":{"execution":{"iopub.execute_input":"2025-10-03T12:39:09.121764Z","iopub.status.busy":"2025-10-03T12:39:09.121402Z","iopub.status.idle":"2025-10-03T12:39:09.738859Z","shell.execute_reply":"2025-10-03T12:39:09.738200Z","shell.execute_reply.started":"2025-10-03T12:39:09.121740Z"},"language":"python","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n","INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"]},{"name":"stdout","output_type":"stream","text":["ðŸ”¹ Follow-up Retrieved Context:\n","- User: Explain context engineering using SingleStore.\n","- Context engineering ensures AI agents always have the right context at the right time.\n","- Assistant: Context engineering in the realm of artificial intelligence and data management involves preparing and optimizing data for use in context-aware applications, such as real-time retrieval-augmented generation (RAG) systems. When leveraging SingleStore for this purpose, it's essential to highlight key features that make it a powerful tool.\n","\n","1. **Low-Latency Queries**: SingleStore is optimized for real-time data processing, which is crucial for RAG applications that rely on immediate access to relevant context. This allows the system to retrieve and analyze data quickly, enabling rapid response times and enhancing user experience.\n","\n","2. **Unified SQL and Vector Search**: One of SingleStore's standout features is its ability to handle both SQL queries and vector searches within the same engine. This unification simplifies the data workflow, allowing developers to seamlessly integrate structured data (managed through SQL) with unstructured data (accessed via vector search). \n","\n","   - **SQL**: Useful for structured data queries, enabling traditional relational database functionalities.\n","   - **Vector Search**: Crucial for dealing with high-dimensional data often used in machine learning applications (like embeddings), making it easier to perform similarity searches and retrieve relevant information based on user queries.\n","\n","3. **Data Preparation and Contextualization**: Through the ability to combine both structured and unstructured data retrieval, context engineering can focus on enriching the user experience. By fine-tuning how data is indexed and retrieved, developers can ensure that the most relevant context is available for AI models and applications in real-time.\n","\n","4. **Performance and Scalability**: SingleStoreâ€™s architecture is designed to scale seamlessly, catering to a high volume of concurrent users and data. This capability allows organizations to handle varying workloads efficiently, crucial for applications needing to deliver consistent performance under different operational demands.\n","\n","Overall, context engineering using SingleStore enables the construction of sophisticated, responsive applications that require immediate access to both structured and unstructured context for enhanced AI-driven decision-making and interactions.\n"]}],"source":["followup_query = \"What did we discuss earlier about context engineering?\"\n","followup_results = vectorstore.similarity_search(followup_query, k=3)\n","\n","print(\"ðŸ”¹ Follow-up Retrieved Context:\")\n","for r in followup_results:\n","    print(\"-\", r.page_content)"]}],"metadata":{"jupyterlab":{"notebooks":{"version_major":6,"version_minor":4}},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"},"singlestore_cell_default_language":"python","singlestore_connection":{"connectionID":"","defaultDatabase":""},"singlestore_row_limit":300},"nbformat":4,"nbformat_minor":5}
